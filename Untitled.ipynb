{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow.contrib.layers import embeding_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "891\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            138\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          554\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "891\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_file = \"train (1).csv\"\n",
    "test_file = \"test (1).csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "print(len(df_train))\n",
    "msk = np.random.rand(len(df_train)) < 0.8\n",
    "print(len(msk))\n",
    "df_test = df_train[~msk]\n",
    "\n",
    "df_train = df_train[msk]\n",
    "print(df_train.isnull().sum())\n",
    "print(len(df_test)+len(df_train))\n",
    "print(len(df_test)+len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Parch</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>22</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>38</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>26</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>35</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>54</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_test))\n",
    "df_train = df_train[[\"Sex\",\"Embarked\",\"Age\",\"Fare\", \"Pclass\", \"Parch\", \"SibSp\",\"Survived\"]].dropna()\n",
    "df_test = df_test[[\"Sex\",\"Embarked\",\"Age\",\"Fare\", \"Pclass\", \"Parch\", \"SibSp\", \"Survived\"]].dropna()\n",
    "\n",
    "# print(df_train)\n",
    "df_train.head()\n",
    "# df_train.Cabin.unique()\n",
    "# print(len(df_train.Cabin.unique()))\n",
    "# print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n"
     ]
    }
   ],
   "source": [
    "# pclass = tf.contrib.layers.sparse_column_with_keys(column_name=\"Pclass\", keys=[1, 2,3])\n",
    "# cabin = tf.contrib.layers.embedding_column(tf.contrib.layers.sparse_column_with_hash_bucket(\"Cabin\", hash_bucket_size=100), dimension=3)\n",
    "sex = tf.contrib.layers.embedding_column(tf.contrib.layers.sparse_column_with_hash_bucket(\"Sex\", hash_bucket_size=2), dimension=3)\n",
    "embarked = tf.contrib.layers.embedding_column(tf.contrib.layers.sparse_column_with_hash_bucket(\"Embarked\", hash_bucket_size=1000), dimension=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"Sex\",\"Embarked\"]\n",
    "CONTINUOUS_COLUMNS = [\"Age\",\"Fare\", \"Pclass\", \"Parch\", \"SibSp\"]\n",
    "LABEL_COLUMN = \"Survived\"\n",
    "\n",
    "def input_fn(df):\n",
    "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "  # the values of that column stored in a constant Tensor.\n",
    "  continuous_cols = {k: tf.constant(df[k].values)\n",
    "                     for k in CONTINUOUS_COLUMNS}\n",
    "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "  # to the values of that column stored in a tf.SparseTensor.\n",
    "  categorical_cols = {k: tf.SparseTensor(\n",
    "      indices=[[i, 0] for i in range(df[k].size)],\n",
    "      values=df[k].values,\n",
    "      shape=[df[k].size, 1])\n",
    "                      for k in CATEGORICAL_COLUMNS}\n",
    "  # Merges the two dictionaries into one.\n",
    "  feature_cols = dict(continuous_cols.items() + categorical_cols.items())\n",
    "  # Converts the label column into a constant Tensor.\n",
    "  label = tf.constant(df[LABEL_COLUMN].values)\n",
    "  # Returns the feature columns and the label.\n",
    "  return feature_cols, label\n",
    "\n",
    "def train_input_fn():\n",
    "  return input_fn(df_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "  return input_fn(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.contrib.layers.real_valued_column(\"Age\")\n",
    "sibsp = tf.contrib.layers.real_valued_column(\"SibSp\")\n",
    "parch = tf.contrib.layers.real_valued_column(\"Parch\")\n",
    "fare = tf.contrib.layers.real_valued_column(\"Fare\")\n",
    "pclass=tf.contrib.layers.real_valued_column(\"Pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/dt/r0mlrq711hzgllmvst1gdx_h0000gn/T/tmptWo6iy\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'save_summary_steps': 100, '_num_ps_replicas': 0, '_task_type': None, '_environment': 'local', '_is_chief': True, 'save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10f53d950>, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, 'tf_random_seed': None, 'keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', 'save_checkpoints_steps': None, '_master': '', 'keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.contrib.learn.DNNClassifier(feature_columns=[\n",
    "   sex, embarked, fare, age,pclass, parch, sibsp],\n",
    "                                   optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.1,\n",
    "#       l1_regularization_strength=0.01,\n",
    "        l2_regularization_strength=0.01\n",
    "        \n",
    "    ),\n",
    "  hidden_units=[64, 32, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/samschickler/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/samschickler/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/samschickler/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 1.47936, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/dt/r0mlrq711hzgllmvst1gdx_h0000gn/T/tmptWo6iy/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.594573, step = 101\n",
      "INFO:tensorflow:global_step/sec: 72.7675\n",
      "INFO:tensorflow:loss = 0.54442, step = 201\n",
      "INFO:tensorflow:global_step/sec: 394.574\n",
      "INFO:tensorflow:loss = 0.522461, step = 301\n",
      "INFO:tensorflow:global_step/sec: 392.423\n",
      "INFO:tensorflow:loss = 0.490246, step = 401\n",
      "INFO:tensorflow:global_step/sec: 403.882\n",
      "INFO:tensorflow:loss = 0.484131, step = 501\n",
      "INFO:tensorflow:global_step/sec: 391.968\n",
      "INFO:tensorflow:loss = 0.485128, step = 601\n",
      "INFO:tensorflow:global_step/sec: 421.058\n",
      "INFO:tensorflow:loss = 0.476951, step = 701\n",
      "INFO:tensorflow:global_step/sec: 401.076\n",
      "INFO:tensorflow:loss = 0.48641, step = 801\n",
      "INFO:tensorflow:global_step/sec: 406.217\n",
      "INFO:tensorflow:loss = 0.46085, step = 901\n",
      "INFO:tensorflow:global_step/sec: 417.798\n",
      "INFO:tensorflow:loss = 0.458214, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 349.291\n",
      "INFO:tensorflow:loss = 0.452111, step = 1101\n",
      "INFO:tensorflow:global_step/sec: 410.507\n",
      "INFO:tensorflow:loss = 0.46256, step = 1201\n",
      "INFO:tensorflow:global_step/sec: 322.3\n",
      "INFO:tensorflow:loss = 0.469187, step = 1301\n",
      "INFO:tensorflow:global_step/sec: 419.599\n",
      "INFO:tensorflow:loss = 0.456918, step = 1401\n",
      "INFO:tensorflow:global_step/sec: 421.647\n",
      "INFO:tensorflow:loss = 0.445564, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 310.348\n",
      "INFO:tensorflow:loss = 0.450515, step = 1601\n",
      "INFO:tensorflow:global_step/sec: 228.492\n",
      "INFO:tensorflow:loss = 0.453924, step = 1701\n",
      "INFO:tensorflow:global_step/sec: 304.137\n",
      "INFO:tensorflow:loss = 0.452479, step = 1801\n",
      "INFO:tensorflow:global_step/sec: 340.213\n",
      "INFO:tensorflow:loss = 0.448636, step = 1901\n",
      "INFO:tensorflow:global_step/sec: 345.319\n",
      "INFO:tensorflow:loss = 0.448305, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 371.995\n",
      "INFO:tensorflow:loss = 0.444543, step = 2101\n",
      "INFO:tensorflow:global_step/sec: 322.332\n",
      "INFO:tensorflow:loss = 0.444838, step = 2201\n",
      "INFO:tensorflow:global_step/sec: 279.143\n",
      "INFO:tensorflow:loss = 0.448024, step = 2301\n",
      "INFO:tensorflow:global_step/sec: 269.801\n",
      "INFO:tensorflow:loss = 0.44449, step = 2401\n",
      "INFO:tensorflow:global_step/sec: 286.284\n",
      "INFO:tensorflow:loss = 0.441069, step = 2501\n",
      "INFO:tensorflow:global_step/sec: 336.181\n",
      "INFO:tensorflow:loss = 0.444292, step = 2601\n",
      "INFO:tensorflow:global_step/sec: 357.829\n",
      "INFO:tensorflow:loss = 0.443159, step = 2701\n",
      "INFO:tensorflow:global_step/sec: 307.402\n",
      "INFO:tensorflow:loss = 0.438842, step = 2801\n",
      "INFO:tensorflow:global_step/sec: 316.266\n",
      "INFO:tensorflow:loss = 0.440143, step = 2901\n",
      "INFO:tensorflow:global_step/sec: 273.119\n",
      "INFO:tensorflow:loss = 0.439066, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 188.377\n",
      "INFO:tensorflow:loss = 0.43837, step = 3101\n",
      "INFO:tensorflow:global_step/sec: 300.291\n",
      "INFO:tensorflow:loss = 0.437173, step = 3201\n",
      "INFO:tensorflow:global_step/sec: 347.302\n",
      "INFO:tensorflow:loss = 0.437252, step = 3301\n",
      "INFO:tensorflow:global_step/sec: 340.506\n",
      "INFO:tensorflow:loss = 0.43643, step = 3401\n",
      "INFO:tensorflow:global_step/sec: 325.534\n",
      "INFO:tensorflow:loss = 0.435069, step = 3501\n",
      "INFO:tensorflow:global_step/sec: 400.344\n",
      "INFO:tensorflow:loss = 0.438982, step = 3601\n",
      "INFO:tensorflow:global_step/sec: 314.614\n",
      "INFO:tensorflow:loss = 0.436224, step = 3701\n",
      "INFO:tensorflow:global_step/sec: 349.975\n",
      "INFO:tensorflow:loss = 0.434197, step = 3801\n",
      "INFO:tensorflow:global_step/sec: 355.712\n",
      "INFO:tensorflow:loss = 0.434017, step = 3901\n",
      "INFO:tensorflow:global_step/sec: 288.143\n",
      "INFO:tensorflow:loss = 0.43279, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 240.258\n",
      "INFO:tensorflow:loss = 0.433901, step = 4101\n",
      "INFO:tensorflow:global_step/sec: 327.378\n",
      "INFO:tensorflow:loss = 0.432469, step = 4201\n",
      "INFO:tensorflow:global_step/sec: 352.215\n",
      "INFO:tensorflow:loss = 0.43491, step = 4301\n",
      "INFO:tensorflow:global_step/sec: 318.5\n",
      "INFO:tensorflow:loss = 0.434111, step = 4401\n",
      "INFO:tensorflow:global_step/sec: 320.334\n",
      "INFO:tensorflow:loss = 0.434179, step = 4501\n",
      "INFO:tensorflow:global_step/sec: 285.987\n",
      "INFO:tensorflow:loss = 0.432405, step = 4601\n",
      "INFO:tensorflow:global_step/sec: 314.527\n",
      "INFO:tensorflow:loss = 0.432045, step = 4701\n",
      "INFO:tensorflow:global_step/sec: 268.523\n",
      "INFO:tensorflow:loss = 0.431405, step = 4801\n",
      "INFO:tensorflow:global_step/sec: 256.613\n",
      "INFO:tensorflow:loss = 0.431425, step = 4901\n",
      "INFO:tensorflow:global_step/sec: 236.293\n",
      "INFO:tensorflow:loss = 0.430492, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 290.256\n",
      "INFO:tensorflow:loss = 0.433198, step = 5101\n",
      "INFO:tensorflow:global_step/sec: 254.706\n",
      "INFO:tensorflow:loss = 0.430262, step = 5201\n",
      "INFO:tensorflow:global_step/sec: 300.291\n",
      "INFO:tensorflow:loss = 0.429647, step = 5301\n",
      "INFO:tensorflow:global_step/sec: 245.174\n",
      "INFO:tensorflow:loss = 0.431719, step = 5401\n",
      "INFO:tensorflow:global_step/sec: 281.25\n",
      "INFO:tensorflow:loss = 0.431289, step = 5501\n",
      "INFO:tensorflow:global_step/sec: 301.128\n",
      "INFO:tensorflow:loss = 0.426851, step = 5601\n",
      "INFO:tensorflow:global_step/sec: 285.478\n",
      "INFO:tensorflow:loss = 0.429891, step = 5701\n",
      "INFO:tensorflow:global_step/sec: 287.834\n",
      "INFO:tensorflow:loss = 0.428977, step = 5801\n",
      "INFO:tensorflow:global_step/sec: 249.069\n",
      "INFO:tensorflow:loss = 0.428898, step = 5901\n",
      "INFO:tensorflow:global_step/sec: 314.804\n",
      "INFO:tensorflow:loss = 0.429953, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 276.366\n",
      "INFO:tensorflow:loss = 0.426223, step = 6101\n",
      "INFO:tensorflow:global_step/sec: 290.879\n",
      "INFO:tensorflow:loss = 0.428667, step = 6201\n",
      "INFO:tensorflow:global_step/sec: 274.425\n",
      "INFO:tensorflow:loss = 0.42799, step = 6301\n",
      "INFO:tensorflow:global_step/sec: 330.309\n",
      "INFO:tensorflow:loss = 0.427999, step = 6401\n",
      "INFO:tensorflow:global_step/sec: 409.646\n",
      "INFO:tensorflow:loss = 0.426746, step = 6501\n",
      "INFO:tensorflow:global_step/sec: 314.465\n",
      "INFO:tensorflow:loss = 0.427186, step = 6601\n",
      "INFO:tensorflow:global_step/sec: 242.738\n",
      "INFO:tensorflow:loss = 0.426133, step = 6701\n",
      "INFO:tensorflow:global_step/sec: 225.856\n",
      "INFO:tensorflow:loss = 0.426083, step = 6801\n",
      "INFO:tensorflow:global_step/sec: 202.355\n",
      "INFO:tensorflow:loss = 0.424101, step = 6901\n",
      "INFO:tensorflow:global_step/sec: 262.939\n",
      "INFO:tensorflow:loss = 0.426732, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 275.435\n",
      "INFO:tensorflow:loss = 0.425295, step = 7101\n",
      "INFO:tensorflow:global_step/sec: 264.802\n",
      "INFO:tensorflow:loss = 0.42811, step = 7201\n",
      "INFO:tensorflow:global_step/sec: 238.809\n",
      "INFO:tensorflow:loss = 0.424626, step = 7301\n",
      "INFO:tensorflow:global_step/sec: 301.546\n",
      "INFO:tensorflow:loss = 0.423523, step = 7401\n",
      "INFO:tensorflow:global_step/sec: 283.615\n",
      "INFO:tensorflow:loss = 0.425357, step = 7501\n",
      "INFO:tensorflow:global_step/sec: 225.161\n",
      "INFO:tensorflow:loss = 0.423709, step = 7601\n",
      "INFO:tensorflow:global_step/sec: 178.938\n",
      "INFO:tensorflow:loss = 0.422393, step = 7701\n",
      "INFO:tensorflow:global_step/sec: 283.72\n",
      "INFO:tensorflow:loss = 0.424474, step = 7801\n",
      "INFO:tensorflow:global_step/sec: 234.529\n",
      "INFO:tensorflow:loss = 0.421805, step = 7901\n",
      "INFO:tensorflow:global_step/sec: 275.487\n",
      "INFO:tensorflow:loss = 0.423236, step = 8001\n",
      "INFO:tensorflow:global_step/sec: 304.946\n",
      "INFO:tensorflow:loss = 0.422219, step = 8101\n",
      "INFO:tensorflow:global_step/sec: 322.206\n",
      "INFO:tensorflow:loss = 0.424582, step = 8201\n",
      "INFO:tensorflow:global_step/sec: 375.766\n",
      "INFO:tensorflow:loss = 0.425108, step = 8301\n",
      "INFO:tensorflow:global_step/sec: 327.291\n",
      "INFO:tensorflow:loss = 0.421282, step = 8401\n",
      "INFO:tensorflow:global_step/sec: 277.215\n",
      "INFO:tensorflow:loss = 0.424104, step = 8501\n",
      "INFO:tensorflow:global_step/sec: 277.383\n",
      "INFO:tensorflow:loss = 0.422199, step = 8601\n",
      "INFO:tensorflow:global_step/sec: 385.808\n",
      "INFO:tensorflow:loss = 0.420673, step = 8701\n",
      "INFO:tensorflow:global_step/sec: 400.232\n",
      "INFO:tensorflow:loss = 0.421218, step = 8801\n",
      "INFO:tensorflow:global_step/sec: 393.398\n",
      "INFO:tensorflow:loss = 0.420147, step = 8901\n",
      "INFO:tensorflow:global_step/sec: 318.6\n",
      "INFO:tensorflow:loss = 0.419949, step = 9001\n",
      "INFO:tensorflow:global_step/sec: 318.501\n",
      "INFO:tensorflow:loss = 0.419288, step = 9101\n",
      "INFO:tensorflow:global_step/sec: 321.649\n",
      "INFO:tensorflow:loss = 0.419587, step = 9201\n",
      "INFO:tensorflow:global_step/sec: 343.806\n",
      "INFO:tensorflow:loss = 0.422346, step = 9301\n",
      "INFO:tensorflow:global_step/sec: 330.2\n",
      "INFO:tensorflow:loss = 0.419564, step = 9401\n",
      "INFO:tensorflow:global_step/sec: 280.321\n",
      "INFO:tensorflow:loss = 0.4197, step = 9501\n",
      "INFO:tensorflow:global_step/sec: 332.091\n",
      "INFO:tensorflow:loss = 0.42195, step = 9601\n",
      "INFO:tensorflow:global_step/sec: 329.9\n",
      "INFO:tensorflow:loss = 0.418636, step = 9701\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 0.419373, step = 9801\n",
      "INFO:tensorflow:global_step/sec: 311.203\n",
      "INFO:tensorflow:loss = 0.420529, step = 9901\n",
      "INFO:tensorflow:global_step/sec: 311.828\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/dt/r0mlrq711hzgllmvst1gdx_h0000gn/T/tmptWo6iy/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 0.416967.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier at 0x10f53de50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(input_fn=train_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/samschickler/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/samschickler/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/samschickler/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Restored model from /var/folders/dt/r0mlrq711hzgllmvst1gdx_h0000gn/T/tmptWo6iy\n",
      "INFO:tensorflow:Eval steps [0,1) for training step 10000.\n",
      "INFO:tensorflow:Saving evaluation summary for step 10000: accuracy = 0.806202, accuracy/baseline_label_mean = 0.341085, accuracy/threshold_0.500000_mean = 0.806202, auc = 0.874866, labels/actual_label_mean = 0.341085, labels/prediction_mean = 0.419628, loss = 0.410105, precision/positive_threshold_0.500000_mean = 0.672727, recall/positive_threshold_0.500000_mean = 0.840909\n",
      "accuracy: 0.806202\n",
      "accuracy/baseline_label_mean: 0.341085\n",
      "accuracy/threshold_0.500000_mean: 0.806202\n",
      "auc: 0.874866\n",
      "global_step: 10000\n",
      "labels/actual_label_mean: 0.341085\n",
      "labels/prediction_mean: 0.419628\n",
      "loss: 0.410105\n",
      "precision/positive_threshold_0.500000_mean: 0.672727\n",
      "recall/positive_threshold_0.500000_mean: 0.840909\n"
     ]
    }
   ],
   "source": [
    "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print \"%s: %s\" % (key, results[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}